---
title: "06_04 Exercises"
output: html_notebook
---

This assessment reviews several concepts about dates, times, and text mining. In part 1 on this page, you will practice extracting and manipulating dates in real datasets. In part 2 on the next page, you will walk through a sentiment analysis of a novel using steps covered in the previous section.<br>

Use the following libraries and options for coding questions:

```{r, include=FALSE}
library(dslabs)
library(lubridate)
library(tidyverse)
options(digits = 3)    # 3 significant digits
```


IMPORTANT: Some of these exercises use dslabs datasets that were added in a July 2019 update. Make sure your package is up to date with the command install.packages("dslabs").<br>

Question 1<br>
1 point possible (graded)<br>
Which of the following is the standard ISO 8601 format for dates?<br>

**Answer: YYYY-MM-DD**


Question 2<br>
1 point possible (graded)<br>
Which of the following commands could convert this string into the correct date format?<br>

      

```{r}
dates <- c("09-01-02", "01-12-07", "02-03-04")
```

**Answer: It is impossible to know which format is correct without additional information.**

Question 3<br>
2 points possible (graded)<br>
Load the brexit_polls data frame from dslabs:<br>

```{r}
data(brexit_polls)
head(brexit_polls)
```

```{r, include = FALSE}
library (tidyverse)
```


How many polls had a start date (startdate) in April (month number 4)?
```{r}
x <- brexit_polls$startdate %>% month() == 4
sum(x)
```
Use the round_date() function on the enddate column with the argument unit="week". <br>
How many polls ended the week of 2016-06-12?
```{r}
y <- round_date(brexit_polls$enddate, unit = "week") == "2016-06-12"
sum(y)
```


Question 4<br>
1 point possible (graded)<br>
Use the weekdays() function from lubridate to determine the weekday on which each poll ended (enddate).<br>
```{r}
z <- weekdays(brexit_polls$enddate)
z[1:10]
```
On which weekday did the greatest number of polls end?
```{r}
table(z)
```

Question 5<br>
0.0/2.0 points (graded)<br>
Load the movielens data frame from dslabs.<br>

```{r}
data(movielens)
head(movielens)
```

This data frame contains a set of about 100,000 movie reviews. The timestamp column contains the review date as the number of seconds since 1970-01-01 (epoch time).<br>

Convert the timestamp column to dates using the lubridate as_datetime() function.<br>

Which year had the most movie reviews?<br>
```{r}
review_date <- as_datetime(movielens$timestamp)
table(year(review_date))

```
Which hour of the day had the most movie reviews?
```{r}
review_date <- as_datetime(movielens$timestamp)
table(hour(review_date))
```

Project Gutenberg is a digital archive of public domain books. The R package gutenbergr facilitates the importation of these texts into R. We will combine this with the tidyverse and tidytext libraries to practice text mining.

Use these libraries and options:

```{r}
library(tidyverse)
library(gutenbergr)
library(tidytext)
options(digits = 3)
```


You can see the books and documents available in gutenbergr like this:
```{r}
gutenberg_metadata
```

```{r}
names(gutenberg_metadata)
```

Use str_detect() to find the ID of the novel Pride and Prejudice.<br>

How many different ID numbers are returned?<br>
```{r}
pattern <- "(P|p)ride and (P|p)rejudice"
gutenberg_metadata %>% filter(str_detect(title, pattern = pattern) == TRUE)
```

Question 7
1 point possible (graded)<br>
Notice that there are several versions of the book. The gutenberg_works() function filters this table to remove replicates and include only English language works. Use this function to find the ID for Pride and Prejudice.

```{r}
pattern <- "(P|p)ride and (P|p)rejudice"

pride_id <- gutenberg_works(
  languages = "en",
  only_text = TRUE,
  distinct = TRUE,
  all_languages = FALSE,
  only_languages = TRUE
)

pride_id %>% filter(str_detect(title, pattern = pattern) == TRUE)
```

What is the correct ID number? <br>
Read the gutenberg_works() documentation to learn how to use the function.

**Answer:1342**

Question 8 <br>
1 point possible (graded)<br>
Use the gutenberg_download() function to download the text for Pride and Prejudice. Use the tidytext package to create a tidy table with all the words in the text. Save this object as words.<br>

```{r}
words <- gutenberg_download(1342)
head(words)
```

How many words are present in the book?
```{r}
nwords <- words %>% unnest_tokens(word, text)
nwords
```




Question 9
1 point possible (graded)

Remove stop words from the words object. Recall that stop words are defined in the stop_words data frame from the tidytext package.

How many words remain?

```{r}

#head(stop_words)

mwords <- nwords %>% filter(!word %in% stop_words$word)
mwords
```


After removing stop words, detect and then filter out any token that contains a digit from words.
```{r}
pattern <- "[0-9]"
has_digit <- mwords %>% filter(str_detect(word, pattern) == TRUE)
#has_digit
pwords <- mwords %>% filter(!word %in% has_digit$word)
pwords
```

How many words remain? <br>
**Answer: 37331**


Analyze the most frequent words in the novel after removing stop words and tokens with digits.<br>
How many words appear more than 100 times in the book?<br>

```{r}
pwords %>% count(word) %>% filter (n > 100)
```


What is the most common word in the book?
```{r}
pwords %>% count(word) %>% filter (n > 100) %>% arrange(desc(n))
```


Question 12 <br>
3 points possible (graded)<br>
Define the afinn lexicon:<br>

```{r}
afinn <- get_sentiments("afinn")
```
   
Note that this command will trigger a question in the R Console asking if you want to download the AFINN lexicon. Press 1 to select "Yes" (if using RStudio, enter this in the Console tab).<br>

Use this afinn lexicon to assign sentiment values to words. Keep only words that are present in both words and the afinn lexicon. Save this data frame as afinn_sentiments.<br>
```{r}
afinn_sentiments <- inner_join(pwords, afinn)
```

How many elements of words have sentiments in the afinn lexicon?
```{r}
afinn_sentiments #%>% filter (!is.na(value))
```

What proportion of words in afinn_sentiments have a positive value?
```{r}
positive <- afinn_sentiments %>% filter(value > 0) %>% nrow()
total <- length(afinn_sentiments$value)

positive/total
```

How many elements of afinn_sentiments have a value of 4?
```{r}
four <- afinn_sentiments %>% filter(value == 4)
four
```



